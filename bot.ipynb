{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO:\n",
    "- Algo seems to only be off by $100, but that's not much in the crypto world.\n",
    "- Need to figure out how to make this more useful. \n",
    "- Next price point isn't bad, but what's the start? I can make a decent model. Now what?\n",
    "    - Figure out how to generate the same data, but now estimate it for the next day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use lagged values to predict current price to forecast price\n",
    "- Notes from this video: https://www.youtube.com/watch?v=xaIA83x5Icg\n",
    " - Create separate transformers for features on different scales\n",
    " - Use this video for building an initial LSTM model\n",
    "- Use this video and it's subsequent one for time series forecasting for BTC using binance exchange data: https://www.youtube.com/watch?v=jR0phoeXjrc\n",
    "    - Use shift to push a column down for matching previous data points to a forecasted point.\n",
    "    - This video is showing how to prep data for a time series model.\n",
    "    - This video is for how to take that preprocessed data and put into PyTorch for the LSTM model: https://www.youtube.com/watch?v=ODEGJ_kh2aA&t=107s\n",
    "         - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(path='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto = pd.read_csv('ETH-USD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in crypto.columns.values:\n",
    "    crypto.rename(columns={\n",
    "        col: col.lower()\n",
    "    }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto.drop('adj close',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_estim = 5\n",
    "output_label = 'next_close_'+str(future_estim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto['next_close_'+str(future_estim)] = crypto['close'].shift(-1*future_estim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = []\n",
    "upper = []\n",
    "lower = []\n",
    "for i in range(window_size):\n",
    "    ma.append(np.nan)\n",
    "    upper.append(np.nan)\n",
    "    lower.append(np.nan)\n",
    "for row in crypto.iterrows():\n",
    "    if row[0] < window_size:\n",
    "        continue\n",
    "#     print(row[0])\n",
    "    mean = np.mean(crypto.iloc[(row[0]-window_size):row[0]]['close'])\n",
    "    ma.append(mean)\n",
    "    std = np.std(crypto.iloc[(row[0]-window_size):row[0]]['close'])\n",
    "    upper.append((mean+std*2))\n",
    "    lower.append((mean-std*2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1827"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto['ma20'] = ma\n",
    "crypto['upper'] = upper\n",
    "crypto['lower'] = lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>next_close_5</th>\n",
       "      <th>ma20</th>\n",
       "      <th>upper</th>\n",
       "      <th>lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-07-12</td>\n",
       "      <td>10.447000</td>\n",
       "      <td>10.762000</td>\n",
       "      <td>10.425800</td>\n",
       "      <td>10.516100</td>\n",
       "      <td>1.112770e+07</td>\n",
       "      <td>11.1587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-07-13</td>\n",
       "      <td>10.506600</td>\n",
       "      <td>10.589500</td>\n",
       "      <td>10.403900</td>\n",
       "      <td>10.500500</td>\n",
       "      <td>6.715660e+06</td>\n",
       "      <td>11.0344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-07-14</td>\n",
       "      <td>10.596900</td>\n",
       "      <td>11.681900</td>\n",
       "      <td>10.596900</td>\n",
       "      <td>11.513200</td>\n",
       "      <td>2.362190e+07</td>\n",
       "      <td>11.6191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-07-15</td>\n",
       "      <td>11.499100</td>\n",
       "      <td>12.431300</td>\n",
       "      <td>11.490000</td>\n",
       "      <td>11.951600</td>\n",
       "      <td>2.683890e+07</td>\n",
       "      <td>12.4506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-07-16</td>\n",
       "      <td>11.919400</td>\n",
       "      <td>11.935900</td>\n",
       "      <td>11.592400</td>\n",
       "      <td>11.652800</td>\n",
       "      <td>1.044570e+07</td>\n",
       "      <td>12.6507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>2021-07-08</td>\n",
       "      <td>2317.949219</td>\n",
       "      <td>2324.006836</td>\n",
       "      <td>2089.414307</td>\n",
       "      <td>2120.026367</td>\n",
       "      <td>2.318812e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2109.220972</td>\n",
       "      <td>2438.549066</td>\n",
       "      <td>1779.892877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>2021-07-09</td>\n",
       "      <td>2115.573975</td>\n",
       "      <td>2185.376221</td>\n",
       "      <td>2051.066650</td>\n",
       "      <td>2146.692383</td>\n",
       "      <td>2.302957e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2103.635632</td>\n",
       "      <td>2428.218001</td>\n",
       "      <td>1779.053263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>2021-07-10</td>\n",
       "      <td>2146.999756</td>\n",
       "      <td>2190.124023</td>\n",
       "      <td>2081.923584</td>\n",
       "      <td>2111.403564</td>\n",
       "      <td>1.758154e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2102.045300</td>\n",
       "      <td>2425.454436</td>\n",
       "      <td>1778.636165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>2021-07-11</td>\n",
       "      <td>2110.875732</td>\n",
       "      <td>2172.653320</td>\n",
       "      <td>2083.803711</td>\n",
       "      <td>2139.664795</td>\n",
       "      <td>1.470539e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2095.297253</td>\n",
       "      <td>2411.940954</td>\n",
       "      <td>1778.653553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>2138.874756</td>\n",
       "      <td>2167.040771</td>\n",
       "      <td>2015.148315</td>\n",
       "      <td>2015.148315</td>\n",
       "      <td>1.711598e+10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2107.858118</td>\n",
       "      <td>2410.295656</td>\n",
       "      <td>1805.420579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1827 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date         open         high          low        close  \\\n",
       "0     2016-07-12    10.447000    10.762000    10.425800    10.516100   \n",
       "1     2016-07-13    10.506600    10.589500    10.403900    10.500500   \n",
       "2     2016-07-14    10.596900    11.681900    10.596900    11.513200   \n",
       "3     2016-07-15    11.499100    12.431300    11.490000    11.951600   \n",
       "4     2016-07-16    11.919400    11.935900    11.592400    11.652800   \n",
       "...          ...          ...          ...          ...          ...   \n",
       "1822  2021-07-08  2317.949219  2324.006836  2089.414307  2120.026367   \n",
       "1823  2021-07-09  2115.573975  2185.376221  2051.066650  2146.692383   \n",
       "1824  2021-07-10  2146.999756  2190.124023  2081.923584  2111.403564   \n",
       "1825  2021-07-11  2110.875732  2172.653320  2083.803711  2139.664795   \n",
       "1826  2021-07-12  2138.874756  2167.040771  2015.148315  2015.148315   \n",
       "\n",
       "            volume  next_close_5         ma20        upper        lower  \n",
       "0     1.112770e+07       11.1587          NaN          NaN          NaN  \n",
       "1     6.715660e+06       11.0344          NaN          NaN          NaN  \n",
       "2     2.362190e+07       11.6191          NaN          NaN          NaN  \n",
       "3     2.683890e+07       12.4506          NaN          NaN          NaN  \n",
       "4     1.044570e+07       12.6507          NaN          NaN          NaN  \n",
       "...            ...           ...          ...          ...          ...  \n",
       "1822  2.318812e+10           NaN  2109.220972  2438.549066  1779.892877  \n",
       "1823  2.302957e+10           NaN  2103.635632  2428.218001  1779.053263  \n",
       "1824  1.758154e+10           NaN  2102.045300  2425.454436  1778.636165  \n",
       "1825  1.470539e+10           NaN  2095.297253  2411.940954  1778.653553  \n",
       "1826  1.711598e+10           NaN  2107.858118  2410.295656  1805.420579  \n",
       "\n",
       "[1827 rows x 10 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cols = []\n",
    "for col in crypto.columns.values:\n",
    "    if 'next' not in col and 'date' not in col and 'adj' not in col:\n",
    "        training_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['open', 'high', 'low', 'close', 'volume', 'ma20', 'upper', 'lower']"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(df, label,training_cols, time_steps):\n",
    "    minmax = {}\n",
    "    for col in training_cols:\n",
    "        temp_minmax = MinMaxScaler()\n",
    "        df[col] = temp_minmax.fit_transform(df[[col]])\n",
    "        minmax.update({col: temp_minmax})\n",
    "    X = df[training_cols]\n",
    "    y = df[label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "    output = compare_rg(X_train, y_train, X_test, y_test, time_steps)\n",
    "    return output, minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_rg(X_train, y_train, X_test, y_test, time_steps):\n",
    "    classifiers = {\n",
    "        'XGBR': XGBRegressor(),\n",
    "        'NN': neural_net(X_train.shape, time_steps)\n",
    "    }\n",
    "\n",
    "    outputs = {\n",
    "        'XGBR': [],\n",
    "        'NN': []\n",
    "    }\n",
    "    for model in classifiers:\n",
    "        if model == 'NN':            \n",
    "            algo = classifiers[model]\n",
    "            X_train, y_train = create_dataset(X_train, y_train, time_steps)\n",
    "            X_test, y_test = create_dataset(X_test, y_test, time_steps)\n",
    "            algo.fit(X_train, y_train, X_test, y_test)\n",
    "        else:\n",
    "            algo = classifiers[model]\n",
    "            algo.fit(X_train, y_train)\n",
    "            y_predict = algo.predict(X_test)\n",
    "            print(\" \")\n",
    "            print(model, ': ',mse(y_test, y_predict))\n",
    "        for output in outputs:\n",
    "            if output == model:\n",
    "                outputs[output] = algo\n",
    "        print('')\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/use-features-lstm-networks-time-series-forecasting/\n",
    "# https://www.kdnuggets.com/2018/11/keras-long-short-term-memory-lstm-model-predict-stock-prices.html\n",
    "class neural_net:\n",
    "    def __init__(self, shape_input, time_steps):\n",
    "        self.shape_input = shape_input\n",
    "        self.model = models.Sequential()\n",
    "        self.batch_size = 32\n",
    "        self.model.add(layers.Bidirectional(\n",
    "            layers.LSTM(units=8, input_shape=(time_steps, shape_input[1]), return_sequences=False)\n",
    "        ))\n",
    "        self.model.add(layers.Dropout(0.2, name='dropout_0'))\n",
    "        self.model.add(layers.Dense(40, activation='relu'))\n",
    "        self.model.add(layers.Dense(1, activation='relu'))\n",
    "        self.model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "#         print(self.model.summary())\n",
    "\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_test, y_test):\n",
    "        self.model.fit(x=X_train, y=y_train, batch_size = self.batch_size, epochs=50, shuffle=False, validation_split=0.1)\n",
    "        evaluation = self.model.evaluate(X_test, y_test)\n",
    "        print(evaluation)\n",
    "    \n",
    "    def predict(self, Xnew):\n",
    "        yNew = self.model.predict_classes(Xnew)\n",
    "        return yNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, y, time_steps = 20):\n",
    "    y = y.values\n",
    "    Xs, ys = [] , []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X[i: (i+time_steps)]\n",
    "        Xs.append(v.values)\n",
    "        ys.append(y[(i+time_steps)])\n",
    "    return np.array(Xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "XGBR :  6627.872553429373\n",
      "\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 1s 20ms/step - loss: 617420.9375 - val_loss: 884140.1250\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 615106.3750 - val_loss: 877900.9375\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 607134.2500 - val_loss: 865959.0625\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 595600.3750 - val_loss: 850209.1875\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 580911.5625 - val_loss: 831615.2500\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 564461.1250 - val_loss: 811443.7500\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 547118.2500 - val_loss: 790351.7500\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 529318.1875 - val_loss: 768805.0000\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 511954.8750 - val_loss: 747538.0625\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 496381.4375 - val_loss: 727319.6250\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 479235.4062 - val_loss: 708159.3125\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 464808.5000 - val_loss: 690750.9375\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 455980.7812 - val_loss: 675633.6250\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 445097.4375 - val_loss: 662442.9375\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 435130.4062 - val_loss: 651093.4375\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 427886.2812 - val_loss: 641741.6250\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 425444.9375 - val_loss: 634282.7500\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 418289.0000 - val_loss: 628060.1875\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 416104.9375 - val_loss: 623203.5625\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 412629.2500 - val_loss: 619407.4375\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 416589.2500 - val_loss: 616726.5000\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 414391.7188 - val_loss: 614762.0625\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 414297.1875 - val_loss: 613118.1250\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 412378.2188 - val_loss: 611788.0625\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 410240.7188 - val_loss: 610836.5000\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 409324.2188 - val_loss: 609989.3750\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 410086.3438 - val_loss: 609363.3750\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 408534.3438 - val_loss: 608855.3750\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 411108.7500 - val_loss: 608651.8125\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 410620.6250 - val_loss: 608370.6250\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 410536.1250 - val_loss: 608161.7500\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 412162.5312 - val_loss: 608025.2500\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 408169.2500 - val_loss: 607822.3750\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 411389.1250 - val_loss: 607679.9375\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 410815.4688 - val_loss: 607742.4375\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 414508.7500 - val_loss: 607785.7500\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 409648.5312 - val_loss: 607688.1875\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 411690.6250 - val_loss: 607653.6875\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 408968.3750 - val_loss: 607674.1250\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 408835.5000 - val_loss: 607445.4375\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 410524.0625 - val_loss: 607438.8750\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 409962.3750 - val_loss: 607344.5000\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 414593.2500 - val_loss: 607513.2500\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 411163.0312 - val_loss: 607516.5000\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 0s 6ms/step - loss: 412404.1250 - val_loss: 607518.8125\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 410203.5938 - val_loss: 607583.8750\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 408803.7500 - val_loss: 607499.0625\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 411973.2812 - val_loss: 607504.6875\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 414388.2500 - val_loss: 607655.3125\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 0s 5ms/step - loss: 407652.5938 - val_loss: 607532.9375\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 276586.0000\n",
      "276586.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output, minmax = train_models(crypto, output_label,training_cols, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = output['XGBR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-370-11aaccea1240>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminmax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrypto\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtraining_cols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'transform'"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(minmax.transform(crypto[training_cols]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto['predicted_close'] = y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto = crypto.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = crypto['next_close'].tolist()\n",
    "y_predict = crypto['predicted_close'].tolist()\n",
    "y_ma = crypto['ma20'].tolist()\n",
    "y_upper = crypto['upper'].tolist()\n",
    "y_lower = crypto['lower'].tolist()\n",
    "x = crypto['date'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(40,20))\n",
    "plt.plot(x, y_predict, label='ETH')\n",
    "plt.plot(x, y_true, label='ETH-Est')\n",
    "plt.plot(x, y_ma, label='20 Day MA')\n",
    "plt.plot(x, y_upper, label='Upper Bound')\n",
    "plt.plot(x, y_lower, label='Lower Bound')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://api.pro.coinbase.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = '/products'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = '/book?level='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = '/stats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only shows best bid and ask\n",
    "level_1 = '1'\n",
    "#Only shows top 50 bids and asks\n",
    "level_2 = '2'\n",
    "#Shows all bids and asks\n",
    "level_3 = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr1 = 'ETH'\n",
    "curr2 = 'USD'\n",
    "pair = '/' + curr1 + '-' + curr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(base_url+products+pair+stats).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_eval = pd.DataFrame(response, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_eval.drop('volume_30day', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_eval.rename(columns={\n",
    "    'last': 'close'\n",
    "},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_eval['ma20'] = np.mean(crypto.iloc[(crypto.shape[0]-window_size-1): (crypto.shape[0]-1)]['ma20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_eval['upper'] = np.std(crypto.iloc[(crypto.shape[0]-window_size-1): (crypto.shape[0]-1)]['ma20'])*2 + np.mean(crypto.iloc[(crypto.shape[0]-window_size-1): (crypto.shape[0]-1)]['ma20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_eval['lower'] = np.mean(crypto.iloc[(crypto.shape[0]-window_size-1): (crypto.shape[0]-1)]['ma20']) - np.std(crypto.iloc[(crypto.shape[0]-window_size-1): (crypto.shape[0]-1)]['ma20'])*2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evald = minmax.transform(to_eval[training_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(evald)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_eval['predicted_close'] = result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto = crypto.append(to_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto = crypto.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in crypto[['date', 'next_close', 'predicted_close']].iterrows():\n",
    "    print(row[1]['date'])\n",
    "    close = np.round(row[1]['next_close'])\n",
    "    predicted_close = np.round(row[1]['predicted_close'])\n",
    "    print('Next Close: ', close)\n",
    "    print('Predicted Close: ', predicted_close)\n",
    "    print('The diff: ', (close - predicted_close))\n",
    "    print(' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
